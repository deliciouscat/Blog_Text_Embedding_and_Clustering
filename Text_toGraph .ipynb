{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 368
    },
    "executionInfo": {
     "elapsed": 420,
     "status": "error",
     "timestamp": 1646023395316,
     "user": {
      "displayName": "구선모",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj4XqiKfZljLd1FvDThTSlEv2JXgBd5cXYFG--d=s64",
      "userId": "09818723858892330013"
     },
     "user_tz": -540
    },
    "id": "Nhne0ZgFuIhJ",
    "outputId": "91d50298-abf8-49ae-a2b2-957e8841daf0"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import dgl\n",
    "import torch\n",
    "\n",
    "from collections import defaultdict\n",
    "from sklearn.decomposition import PCA\n",
    "import joblib\n",
    "from dgl.data.utils import save_graphs, load_graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S0zpiZJTuqPG"
   },
   "outputs": [],
   "source": [
    "data_postEmb=np.load('/content/drive/MyDrive/BlogAuthorClass/postEmb_384dim_Mono(6).npy', allow_pickle=True)\n",
    "pca=joblib.load('/content/drive/MyDrive/BlogAuthorClass/PCA_Mono384.pkl')\n",
    "text=pd.read_csv(\"/content/drive/MyDrive/BlogAuthorClass/blogtext_2sent.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HIZk_vB5u7LV"
   },
   "outputs": [],
   "source": [
    "window_size=2\n",
    "device = torch.device('cuda')\n",
    "post_graph_list=[]\n",
    "\n",
    "def convert_bool2int(inp):\n",
    "    return node_bool2int[inp]\n",
    "\n",
    "for postEmb in data_postEmb:\n",
    "    node_dict=defaultdict(list)\n",
    "    src_dict=defaultdict(list)\n",
    "    dst_dict=defaultdict(list)\n",
    "    sliding_window=[]\n",
    "    node_attribute=[]\n",
    "    \n",
    "    post_sentwise_clu = pca.transform(postEmb)<0    # dividing latent space for clustering\n",
    "    for sent_clu, sent_emb in zip(post_sentwise_clu, postEmb):\n",
    "        sent_clu=tuple(sent_clu)\n",
    "        node_dict[sent_clu].append(sent_emb)        # node features\n",
    "\n",
    "        temp_ws=len(sliding_window)\n",
    "        for i in range(temp_ws):\n",
    "            src_dict[str(i+1)+\"hop\"].append(sliding_window[temp_ws-1-i])\n",
    "            dst_dict[str(i+1)+\"hop\"].append(sent_clu)\n",
    "            \n",
    "            \n",
    "        sliding_window.append(sent_clu)\n",
    "        if len(sliding_window) > window_size:\n",
    "            sliding_window.pop(0)\n",
    "\n",
    "            \n",
    "    sent_nodes = node_dict.keys()\n",
    "    node_bool2int = defaultdict()\n",
    "    for nodeBool,nodeInt in zip(sent_nodes, range(len(sent_nodes))):\n",
    "        node_bool2int[nodeBool]=nodeInt\n",
    "        node_attribute.append(sum(node_dict[nodeBool])/len(node_dict[nodeBool]))\n",
    "        \n",
    "    \n",
    "    for i in range(window_size):\n",
    "        src_dict[str(i+1)+\"hop\"]=torch.tensor(list(map(convert_bool2int,src_dict[str(i+1)+\"hop\"])))\n",
    "        dst_dict[str(i+1)+\"hop\"]=torch.tensor(list(map(convert_bool2int,dst_dict[str(i+1)+\"hop\"])))\n",
    "    \n",
    "    g=defaultdict()\n",
    "    for i in range(window_size):\n",
    "        g[(\"f\", str(i+1)+\"hop\", \"f\")] = (src_dict[str(i+1)+\"hop\"],dst_dict[str(i+1)+\"hop\"])\n",
    "    \n",
    "    try :\n",
    "        g=dgl.heterograph(g).to_simple(return_counts=\"overlap\").to(device)\n",
    "        g.ndata['f'] = torch.tensor(node_attribute, device='cuda')\n",
    "    except :   # for cases which has fewer or same node numbers then \"window_size\"\n",
    "        g.popitem()\n",
    "        g=dgl.heterograph(g).to_simple(return_counts=\"overlap\").to(device)\n",
    "        g.ndata['f'] = torch.tensor(node_attribute, device='cuda')\n",
    "    \n",
    "    post_graph_list.append(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hNzgLhc6HMVx"
   },
   "outputs": [],
   "source": [
    "save_graphs(\"/content/drive/MyDrive/BlogAuthorClass/post_graph_list(6).bin\", post_graph_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ek_HEvyyJk9H"
   },
   "outputs": [],
   "source": [
    "post_graph_list = load_graphs(\"/content/drive/MyDrive/BlogAuthorClass/post_graph_list(total).bin\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 319
    },
    "executionInfo": {
     "elapsed": 1558,
     "status": "ok",
     "timestamp": 1645856772951,
     "user": {
      "displayName": "구선모",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj4XqiKfZljLd1FvDThTSlEv2JXgBd5cXYFG--d=s64",
      "userId": "09818723858892330013"
     },
     "user_tz": -540
    },
    "id": "XgAQ0SAe7YOG",
    "outputId": "03fe2940-da28-45be-d7be-9624b5dc70c9"
   },
   "outputs": [],
   "source": [
    "nx.draw_kamada_kawai(dgl.to_homogeneous(post_graph_list[43310]).cpu().to_networkx(), node_size=77)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 319
    },
    "executionInfo": {
     "elapsed": 1312,
     "status": "ok",
     "timestamp": 1645856780839,
     "user": {
      "displayName": "구선모",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj4XqiKfZljLd1FvDThTSlEv2JXgBd5cXYFG--d=s64",
      "userId": "09818723858892330013"
     },
     "user_tz": -540
    },
    "id": "kUi_ZW52HhLh",
    "outputId": "c6b6671d-1715-411c-9261-2a0ddc218733"
   },
   "outputs": [],
   "source": [
    "nx.draw_kamada_kawai(post_graph_list[43310][('f','1hop','f')].cpu().to_networkx(), node_size=77)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FSB_ppTmSw_W"
   },
   "outputs": [],
   "source": [
    "save_graphs(\"/content/drive/MyDrive/BlogAuthorClass/post_graph_list(total).bin\", post_graph_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ioYhT4iDT8W_"
   },
   "outputs": [],
   "source": [
    "post_graph_list = load_graphs(\"/content/drive/MyDrive/BlogAuthorClass/post_graph_list(total).bin\")[0]"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyOmEqCkqOJVPt0Zs0a9Dgae",
   "collapsed_sections": [],
   "machine_shape": "hm",
   "mount_file_id": "1fXCAfme6wmlJSx5qttUYx8D4CvVem9CZ",
   "name": "Text_toGraph.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
