{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "canvas": {
     "comments": [],
     "componentType": "CodeCell",
     "copiedOriginId": null,
     "headerColor": "none",
     "id": "e93453d5-e57c-4efe-931d-1387987e80ba",
     "isComponent": false,
     "name": "",
     "parents": []
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FpWgiwb2CnRX",
    "outputId": "f06d60eb-203c-42c5-f0f7-2512d557fd12",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting pytorch-metric-learning\n",
      "  Downloading pytorch_metric_learning-1.6.3-py3-none-any.whl (111 kB)\n",
      "\u001b[K     |████████████████████████████████| 111 kB 5.1 MB/s \n",
      "\u001b[?25hRequirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from pytorch-metric-learning) (0.13.1+cu113)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from pytorch-metric-learning) (1.0.2)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from pytorch-metric-learning) (1.21.6)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from pytorch-metric-learning) (4.64.1)\n",
      "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-metric-learning) (1.12.1+cu113)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.6.0->pytorch-metric-learning) (4.1.1)\n",
      "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->pytorch-metric-learning) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->pytorch-metric-learning) (3.1.0)\n",
      "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->pytorch-metric-learning) (1.7.3)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchvision->pytorch-metric-learning) (2.23.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision->pytorch-metric-learning) (7.1.2)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision->pytorch-metric-learning) (1.24.3)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision->pytorch-metric-learning) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision->pytorch-metric-learning) (2022.9.24)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision->pytorch-metric-learning) (2.10)\n",
      "Installing collected packages: pytorch-metric-learning\n",
      "Successfully installed pytorch-metric-learning-1.6.3\n"
     ]
    }
   ],
   "source": [
    "!pip install pytorch-metric-learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "canvas": {
     "comments": [],
     "componentType": "CodeCell",
     "copiedOriginId": null,
     "headerColor": "none",
     "id": "835e1ab0-561a-4158-939e-077e3ec64915",
     "isComponent": false,
     "name": "",
     "parents": []
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a-YKBwZAWuE7",
    "outputId": "27d4b753-e955-4014-982a-6f3d3aae4499"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "canvas": {
     "comments": [],
     "componentType": "CodeCell",
     "copiedOriginId": null,
     "headerColor": "none",
     "id": "dd5b10ff-483e-41c1-9fd4-5176cc3bdde7",
     "isComponent": false,
     "name": "",
     "parents": []
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 340
    },
    "id": "FUt5ifwcCr-r",
    "outputId": "6564ffe0-d7b7-41de-8ba3-003f0cd90310"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "errorDetails": {
      "actions": [
       {
        "action": "open_url",
        "actionText": "Open Examples",
        "url": "/notebooks/snippets/importing_libraries.ipynb"
       }
      ]
     },
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-07422ba2032a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpytorch_metric_learning\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlosses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mminers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdistances\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pytorch_metric_learning'",
      "",
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "import nltk\n",
    "from pytorch_metric_learning import losses, miners, distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "canvas": {
     "comments": [],
     "componentType": "CodeCell",
     "copiedOriginId": null,
     "headerColor": "none",
     "id": "6e56e45d-1399-4d36-8bbf-2db7d66265f2",
     "isComponent": false,
     "name": "",
     "parents": []
    },
    "id": "r9JxTtQFvDno"
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda')\n",
    "data_postEmb = np.concatenate([np.load('/content/drive/MyDrive/BlogAuthorClass/postEmb_384dim_Mono(1).npy',allow_pickle=True),\n",
    "                    np.load('/content/drive/MyDrive/BlogAuthorClass/postEmb_384dim_Mono(2).npy',allow_pickle=True),\n",
    "                    np.load('/content/drive/MyDrive/BlogAuthorClass/postEmb_384dim_Mono(3).npy',allow_pickle=True),\n",
    "                    np.load('/content/drive/MyDrive/BlogAuthorClass/postEmb_384dim_Mono(4).npy',allow_pickle=True),\n",
    "                    np.load('/content/drive/MyDrive/BlogAuthorClass/postEmb_384dim_Mono(5).npy',allow_pickle=True)[:67809],])\n",
    "text = pd.read_csv('/content/drive/MyDrive/BlogAuthorClass/blogtext_2sent.csv')[:467809]\n",
    "\n",
    "#data_postEmb = np.load('/content/drive/MyDrive/BlogAuthorClass/postEmb_384dim_train_top500.npy',allow_pickle=True)\n",
    "#text = pd.read_csv('/content/drive/MyDrive/BlogAuthorClass/blogtext_train_top500(1).csv')\n",
    "\n",
    "data_postEmb = [torch.tensor(sent_seq, device=device) for sent_seq in data_postEmb]\n",
    "ids = torch.tensor(list(text['id']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "canvas": {
     "comments": [],
     "componentType": "CodeCell",
     "copiedOriginId": null,
     "headerColor": "none",
     "id": "12303e9a-4116-45c1-a1dc-26440fbbb8c2",
     "isComponent": false,
     "name": "",
     "parents": []
    },
    "id": "6MOn5ueHAZNe"
   },
   "outputs": [],
   "source": [
    "class BiLSTM_Attention(nn.Module):\n",
    "    def __init__(self, input_dim = 384, n_hidden = 384 , embed_dim = 64, token_emb=192):\n",
    "        super(BiLSTM_Attention, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.n_hidden = n_hidden\n",
    "        self.embed_dim = embed_dim\n",
    "        #self.token_emb = token_emb\n",
    "        self.reduction = nn.Linear(n_hidden*2, n_hidden)\n",
    "\n",
    "        self.gru1 = nn.GRU(input_dim, n_hidden, bidirectional=True, dropout = 0.13)\n",
    "        self.gru2 = nn.GRU(n_hidden, n_hidden, bidirectional=True, dropout = 0.1)\n",
    "        self.fc_layer = nn.Sequential(\n",
    "            nn.Linear(n_hidden * 2, 512),\n",
    "            nn.ELU(inplace=True),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ELU(inplace=True),\n",
    "            nn.Linear(512, 384),  \n",
    "            nn.Dropout(0.13),\n",
    "            nn.ELU(inplace=True),\n",
    "            nn.Linear(384, embed_dim),\n",
    "        )\n",
    "\n",
    "    def attention_net(self, gru_output, final_state):\n",
    "        hidden = final_state.view(-1, self.n_hidden * 2, 1)   # hidden : [batch_size, n_hidden * num_directions(=2), 1(=n_layer)]\n",
    "        attn_weights = torch.bmm(gru_output, hidden).squeeze(2) # attn_weights : [batch_size, n_step]\n",
    "        soft_attn_weights = F.softmax(attn_weights, 1)\n",
    "        # [batch_size, n_hidden * num_directions(=2), n_step] * [batch_size, n_step, 1] = [batch_size, n_hidden * num_directions(=2), 1]\n",
    "        context = torch.bmm(gru_output.transpose(1, 2), soft_attn_weights.unsqueeze(2)).squeeze(2)\n",
    "        return context, soft_attn_weights.data#.numpy() # context : [batch_size, n_hidden * num_directions(=2)]\n",
    "\n",
    "    def forward(self, X):\n",
    "        inp = X.permute(1, 0, 2) # inp : [len_seq, batch_size, embedding_dim]\n",
    "        hidden_state = Variable(torch.zeros(1*2, len(X), self.n_hidden)) # [num_layers(=1) * num_directions(=2), batch_size, n_hidden]\n",
    "        output, _ = self.gru1(inp)\n",
    "        \n",
    "        # Bi-directrional sum\n",
    "        output = self.reduction(output) + inp    # bi-direction concat 후 dense layer로 차원 축소\n",
    "\n",
    "        output, final_hidden_state = self.gru2(output)#.unsqueeze(0))\n",
    "        output = output.permute(1, 0, 2) # output : [batch_size, len_seq, n_hidden]\n",
    "        attn_output, attention = self.attention_net(output, final_hidden_state)\n",
    "        return self.fc_layer(attn_output), attention # model : [batch_size, num_classes], attention : [batch_size, n_step]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "canvas": {
     "comments": [],
     "componentType": "CodeCell",
     "copiedOriginId": null,
     "headerColor": "none",
     "id": "5701539e-82e3-44b3-8fac-ddf032d54225",
     "isComponent": false,
     "name": "",
     "parents": []
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FugkeuLrkkzu",
    "outputId": "a9771008-d501-4c59-9b0a-5b89aa5104bf"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:65: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.13 and num_layers=1\n",
      "  \"num_layers={}\".format(dropout, num_layers))\n",
      "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:65: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  \"num_layers={}\".format(dropout, num_layers))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BiLSTM_Attention(\n",
       "  (reduction): Linear(in_features=768, out_features=384, bias=True)\n",
       "  (gru1): GRU(384, 384, dropout=0.13, bidirectional=True)\n",
       "  (gru2): GRU(384, 384, dropout=0.1, bidirectional=True)\n",
       "  (fc_layer): Sequential(\n",
       "    (0): Linear(in_features=768, out_features=512, bias=True)\n",
       "    (1): ELU(alpha=1.0, inplace=True)\n",
       "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (3): ELU(alpha=1.0, inplace=True)\n",
       "    (4): Linear(in_features=512, out_features=384, bias=True)\n",
       "    (5): Dropout(p=0.13, inplace=False)\n",
       "    (6): ELU(alpha=1.0, inplace=True)\n",
       "    (7): Linear(in_features=384, out_features=64, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net=BiLSTM_Attention(embed_dim=64)\n",
    "#net.load_state_dict(torch.load('/content/drive/MyDrive/BlogAuthorClass/Trained_models/~').state_dict())\n",
    "\n",
    "net.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "canvas": {
     "comments": [],
     "componentType": "CodeCell",
     "copiedOriginId": null,
     "headerColor": "none",
     "id": "a03c95b0-c143-4a7d-a7b4-dc451c9d0d7e",
     "isComponent": false,
     "name": "",
     "parents": []
    },
    "id": "jzawqRQAu_rB"
   },
   "outputs": [],
   "source": [
    "# sequential dataloader 만들기\n",
    "# https://towardsdatascience.com/dataloader-for-sequential-data-using-pytorch-deep-learning-framework-part-2-ed3ad5f6ad82\n",
    "\n",
    "'''\n",
    "\tArgs:\n",
    "\t\tdata: list of tuple (training sequence, label)\n",
    "\tReturn:\n",
    "\t\tpadded_seq - Padded Sequence, tensor of shape (batch_size, padded_length)\n",
    "\t\tlength - Original length of each sequence(without padding), tensor of shape(batch_size)\n",
    "\t\tlabel - tensor of shape (batch_size)\n",
    "'''\n",
    "\n",
    "emb_size=384\n",
    "def collate_fn(data):\n",
    "    #sorting is important for usage pack padded sequence (used in model). It should be in decreasing order.\n",
    "    data.sort(key=lambda x: len(x[0]), reverse=True)\n",
    "    sequences, label = zip(*data)\n",
    "    length = [len(seq) for seq in sequences]\n",
    "    padded_seq = torch.zeros(len(sequences), max(length), emb_size)#.long()\n",
    "    for i, seq in enumerate(sequences):\n",
    "        end = length[i]\n",
    "        padded_seq[i,:end] = seq\n",
    "    return padded_seq, torch.from_numpy(np.array(length)).to(device), torch.from_numpy(np.array(label)).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "canvas": {
     "comments": [],
     "componentType": "CodeCell",
     "copiedOriginId": null,
     "headerColor": "none",
     "id": "8afb814b-bfed-4aaa-998e-f78ebb875f31",
     "isComponent": false,
     "name": "",
     "parents": []
    },
    "id": "4mlsfzC7U2fV"
   },
   "outputs": [],
   "source": [
    "subset_files = ['/content/drive/MyDrive/BlogAuthorClass/postEmb_384dim_Mono(1).npy',\n",
    "                '/content/drive/MyDrive/BlogAuthorClass/postEmb_384dim_Mono(2).npy',\n",
    "                '/content/drive/MyDrive/BlogAuthorClass/postEmb_384dim_Mono(3).npy',\n",
    "                '/content/drive/MyDrive/BlogAuthorClass/postEmb_384dim_Mono(4).npy',\n",
    "                #'/content/drive/MyDrive/BlogAuthorClass/postEmb_384dim_Mono(5).npy',\n",
    "                #'/content/drive/MyDrive/BlogAuthorClass/postEmb_384dim_Mono(6).npy',\n",
    "                ]\n",
    "\n",
    "text = pd.read_csv('/content/drive/MyDrive/BlogAuthorClass/blogtext_2sent.csv')#[100000:300000]\n",
    "device = torch.device('cuda')\n",
    "\n",
    "def sample_subset(files, nums=2) :\n",
    "    samples = np.sort(np.random.choice(range(len(files)),size=nums, replace=False))\n",
    "    outemb = [np.load(files[s], allow_pickle=True) for s in samples]\n",
    "    begin, end = samples*100000, samples*100000 + 100000\n",
    "    outtxt = [text[b:e] for b,e in zip(begin, end)]\n",
    "    return list(np.concatenate(outemb)), pd.concat(outtxt)\n",
    "#data_postEmb, subtxt = sample_subset(subset_files)\n",
    "#data_postEmb = [torch.tensor(sent_seq, device=device) for sent_seq in data_postEmb]\n",
    "#ids = torch.tensor(list(subtxt['id']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "canvas": {
     "comments": [],
     "componentType": "CodeCell",
     "copiedOriginId": null,
     "headerColor": "none",
     "id": "c6817e04-90ab-425c-a9a5-e033aae66b66",
     "isComponent": false,
     "name": "",
     "parents": []
    },
    "id": "Me4EQ_mj5N8z"
   },
   "outputs": [],
   "source": [
    "# fixed train\n",
    "data_postEmb = np.load('/content/drive/MyDrive/BlogAuthorClass/SampledID/postEmb_384dim_10samples(train).npy',allow_pickle=True)\n",
    "text = pd.read_csv('/content/drive/MyDrive/BlogAuthorClass/SampledID/blogtext_train_sample(10ids).csv')\n",
    "\n",
    "data_postEmb = [torch.tensor(sent_seq, device=device) for sent_seq in data_postEmb]\n",
    "ids = torch.tensor(list(text['id']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "canvas": {
     "comments": [],
     "componentType": "CodeCell",
     "copiedOriginId": null,
     "headerColor": "none",
     "id": "0ad92c4b-d69c-454e-98de-20c2eb780359",
     "isComponent": false,
     "name": "",
     "parents": []
    },
    "id": "DOmSNCZR7TSv"
   },
   "outputs": [],
   "source": [
    "# validation set\n",
    "\n",
    "device = torch.device('cuda')\n",
    "test_postEmb = np.load('/content/drive/MyDrive/BlogAuthorClass/postEmb_384dim_test_top500.npy',allow_pickle=True)\n",
    "test_text = pd.read_csv('/content/drive/MyDrive/BlogAuthorClass/blogtext_test_top500(1).csv')\n",
    "\n",
    "test_postEmb = [torch.tensor(sent_seq, device=device) for sent_seq in test_postEmb]\n",
    "test_ids = torch.tensor(list(test_text['id']))\n",
    "\n",
    "testloader = DataLoader(list(zip(test_postEmb, test_ids)),\n",
    "                        batch_size=300,\n",
    "                        #batch_size=64,\n",
    "                        shuffle=True,\n",
    "                        collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "canvas": {
     "comments": [],
     "componentType": "CodeCell",
     "copiedOriginId": null,
     "headerColor": "none",
     "id": "9ca7cdf3-3b84-4e13-a2b7-9d1f7042a187",
     "isComponent": false,
     "name": "",
     "parents": []
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 241
    },
    "id": "mB_7N4eBxqzf",
    "outputId": "c7836fbe-ef71-42b9-c140-fb1ed7b92abf"
   },
   "outputs": [],
   "source": [
    "#train\n",
    "dataloader = DataLoader(list(zip(data_postEmb, ids)),\n",
    "                        #batch_size=100,\n",
    "                        batch_size=64,\n",
    "                        shuffle=True,\n",
    "                        collate_fn=collate_fn)\n",
    "#validation\n",
    "testloader = DataLoader(list(zip(test_postEmb, test_ids)),\n",
    "                        batch_size=300,\n",
    "                        #batch_size=64,\n",
    "                        shuffle=True,\n",
    "                        collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "canvas": {
     "comments": [],
     "componentType": "CodeCell",
     "copiedOriginId": null,
     "headerColor": "none",
     "id": "f8bb1495-4a1b-4ff8-8aa7-2f2a5af81757",
     "isComponent": false,
     "name": "",
     "parents": []
    },
    "id": "c6lhf4YWj2az"
   },
   "outputs": [],
   "source": [
    "train_loss_list = []\n",
    "test_loss_list = []\n",
    "#train_loss_list = np.load('/content/drive/MyDrive/BlogAuthorClass/KPS/v13_tr_loss(Lifted0p05Pos01_lr0p002_400epo(120best)).npy').tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "canvas": {
     "comments": [],
     "componentType": "CodeCell",
     "copiedOriginId": null,
     "headerColor": "none",
     "id": "fe5f5e1b-348e-4b9f-801c-444655347e00",
     "isComponent": false,
     "name": "",
     "parents": []
    },
    "id": "yBZT7dNzASTJ"
   },
   "outputs": [],
   "source": [
    "#miner = miners.MultiSimilarityMiner()\n",
    "miner = miners.TripletMarginMiner(margin=0.2,\n",
    "                                  #margin=0.15,\n",
    "                          type_of_triplets=\"semihard\",)\n",
    "                          #type_of_triplets=\"hard\")  # all hard semihard easy\n",
    "#loss_func = losses.TripletMarginLoss(#margin=0.05,\n",
    "#                                     margin=0.5,\n",
    "#                                     swap=True,\n",
    "#                                     #smooth_loss=True,\n",
    "#                                     triplets_per_anchor=64)\n",
    "loss_func = losses.LiftedStructureLoss(neg_margin=0.05, # baseline\n",
    "                                       pos_margin=0.01, # baseline\n",
    "                                       distance=distances.LpDistance(p=2.))#,normalize_embeddings=False))\n",
    "\n",
    "\n",
    "optimizer = optim.Adam(net.parameters(), lr = 0.0002)   #0.00000005\n",
    "scheduler = optim.lr_scheduler.LambdaLR(optimizer=optimizer,\n",
    "                                        lr_lambda=lambda step: 0.995 ** step,\n",
    "                                        last_epoch=-1,\n",
    "                                        verbose=False)\n",
    "\n",
    "#train_loss_list=[]\n",
    "#val_accuracy=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "canvas": {
     "comments": [],
     "componentType": "CodeCell",
     "copiedOriginId": null,
     "headerColor": "none",
     "id": "9c8d2772-43c5-4161-a420-edad0708a213",
     "isComponent": false,
     "name": "",
     "parents": []
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FmXqPkSTw29z",
    "outputId": "1f003a2b-f4d8-4e05-8dc2-4490b509220e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adam\n",
      "Epoch : 0 Train_Loss :  3.614785118342036\n",
      "1.0 808\n",
      "Epoch : 1 Train_Loss :  3.607934481436663\n",
      "1.0 1616\n",
      "Epoch : 2 Train_Loss :  3.5908882188619953\n",
      "1.0 2424\n",
      "Epoch : 3 Train_Loss :  3.6300947649939226\n",
      "1.0 3232\n",
      "Epoch : 4 Train_Loss :  3.578184699067975\n",
      "1.0 4040\n",
      "Epoch : 5 Train_Loss :  3.5888605080176106\n",
      "1.0 4848\n",
      "Epoch : 6 Train_Loss :  3.6622183972065994\n",
      "1.0 5656\n",
      "Epoch : 7 Train_Loss :  3.663795183643256\n",
      "1.0 6464\n",
      "Epoch : 8 Train_Loss :  3.6189186385657526\n",
      "1.0 7272\n",
      "Epoch : 9 Train_Loss :  3.6581105918872474\n",
      "1.0 8080\n",
      "Epoch : 10 Train_Loss :  3.5981202280462377\n",
      "1.0 8888\n",
      "Epoch : 11 Train_Loss :  3.6091211182941305\n",
      "1.0 9696\n",
      "Epoch : 12 Train_Loss :  3.616771696965293\n",
      "1.0 10504\n",
      "Epoch : 13 Train_Loss :  3.594706532683703\n",
      "1.0 11312\n",
      "Epoch : 14 Train_Loss :  3.6202710606526622\n",
      "1.0 12120\n",
      "Epoch : 15 Train_Loss :  3.6735290830383205\n",
      "1.0 12928\n",
      "Epoch : 16 Train_Loss :  3.5996536963646957\n",
      "1.0 13736\n",
      "Epoch : 17 Train_Loss :  3.592785271345684\n",
      "1.0 14544\n",
      "Epoch : 18 Train_Loss :  3.665264377499571\n",
      "1.0 15352\n",
      "Epoch : 19 Train_Loss :  3.5908694656768647\n",
      "1.0 16160\n",
      "Epoch : 20 Train_Loss :  3.59550285081167\n",
      "1.0 16968\n",
      "Epoch : 21 Train_Loss :  3.5801237098651355\n",
      "1.0 17776\n",
      "Epoch : 22 Train_Loss :  3.5570557120412882\n",
      "1.0 18584\n",
      "Epoch : 23 Train_Loss :  3.579389824725614\n",
      "1.0 19392\n",
      "Epoch : 24 Train_Loss :  3.5546799585370734\n",
      "1.0 20200\n",
      "Epoch : 25 Train_Loss :  3.5697487333033346\n",
      "1.0 21008\n",
      "Epoch : 26 Train_Loss :  3.580587587586724\n",
      "1.0 21816\n",
      "Epoch : 27 Train_Loss :  3.6061844451002556\n",
      "1.0 22624\n",
      "Epoch : 28 Train_Loss :  3.5307185075955814\n",
      "1.0 23432\n",
      "Epoch : 29 Train_Loss :  3.566752485562079\n",
      "1.0 24240\n"
     ]
    }
   ],
   "source": [
    "suc=0\n",
    "fal=0\n",
    "\n",
    "print(\"Adam\")\n",
    "for epoch in range(30):\n",
    "    \n",
    "    ###  RAM 용적이 제한된 경우, 학습 데이터를 shuffle해가며 학습  ###\n",
    "    #data_postEmb, subtxt = sample_subset(subset_files)\n",
    "    #data_postEmb = [torch.tensor(sent_seq, device=device) for sent_seq in data_postEmb]\n",
    "    #ids = torch.tensor(list(subtxt['id']))\n",
    "    #dataloader = DataLoader(list(zip(data_postEmb, list(subtxt['id']))),\n",
    "    #                        batch_size=384,\n",
    "    #                        shuffle=True,\n",
    "    #                        collate_fn=collate_fn)\n",
    "    train_loss = 0\n",
    "    for data, _, labels in dataloader :\n",
    "        net.train()   # dropout on\n",
    "        try :\n",
    "            optimizer.zero_grad()\n",
    "            embeddings = net(data.cuda())\n",
    "            hard_pairs = miner(embeddings[0], labels)\n",
    "            loss = loss_func(embeddings[0], labels, hard_pairs)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "            gc.collect()\n",
    "            torch.cuda.empty_cache()\n",
    "            suc+=1\n",
    "        except Exception as e :\n",
    "            print(e)\n",
    "            fal+=1\n",
    "    \n",
    "        #test_loss = 0\n",
    "        #for data_te, __, labels_te in testloader :\n",
    "        #    net.eval()    # dropout off\n",
    "        #    embeddings = net(data_te.cuda())\n",
    "        #    hard_pairs = miner(embeddings[0], labels_te)\n",
    "        #    test_loss += loss_func(embeddings[0], labels_te, hard_pairs).item()\n",
    "    \n",
    "    scheduler.step()\n",
    "    test_loss_list.append(test_loss / len(testloader))\n",
    "    train_loss_list.append(train_loss / len(dataloader))\n",
    "    #del \n",
    "\n",
    "    #if epoch % 2 == 0:\n",
    "    #    print(\"Epoch :\", epoch, \"Loss : \", loss)\n",
    "    #    print(suc/(suc+fal), suc)\n",
    "    print(\"Epoch :\", epoch, \"Train_Loss : \", train_loss / len(dataloader),)# \"Test_Loss : \", test_loss)\n",
    "    print(suc/(suc+fal), suc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "canvas": {
     "comments": [],
     "componentType": "CodeCell",
     "copiedOriginId": null,
     "headerColor": "none",
     "id": "47c905ae-9fc3-4d7b-80d9-ddc443a57133",
     "isComponent": false,
     "name": "",
     "parents": []
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "id": "EUbarR0dSdBy",
    "outputId": "42ed2461-7296-44c7-f8a8-e0c356b2d3c9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fbfeee6c810>]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_loss_list[85:])\n",
    "#plt.plot(test_loss_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "canvas": {
     "comments": [],
     "componentType": "CodeCell",
     "copiedOriginId": null,
     "headerColor": "none",
     "id": "6c6db121-0a98-47a9-812b-49bdc71cf0db",
     "isComponent": false,
     "name": "",
     "parents": []
    },
    "id": "2E2U30LVtCNp"
   },
   "outputs": [],
   "source": [
    "#torch.save(net,\"/content/drive/MyDrive/BlogAuthorClass/KPS/GRUmodel_v13(Lifted0p05Pos01_file1_top500_margin0p05_KPS)(lr0p001_500epo_end)\")\n",
    "torch.save(net,\"/content/drive/MyDrive/BlogAuthorClass/KPS/GRUmodel_v13(Lifted0p05Pos01_file1_top500_margin0p05_KPS)(잡탕)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "canvas": {
     "comments": [],
     "componentType": "CodeCell",
     "copiedOriginId": null,
     "headerColor": "none",
     "id": "d2f885d5-bc88-417f-9a25-9d853e24b837",
     "isComponent": false,
     "name": "",
     "parents": []
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 236
    },
    "id": "3RGUP8vPVRch",
    "outputId": "82acd981-b862-4932-e7b1-b929bc65e1f9"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-fc4bdf9c7184>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#del dataloader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m dataloader = DataLoader(list(zip(data_postEmb, ids)),\n\u001b[0m\u001b[1;32m      3\u001b[0m                         \u001b[0;31m#batch_size=384,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                         \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'data_postEmb' is not defined"
     ]
    }
   ],
   "source": [
    "#dataloader\n",
    "dataloader = DataLoader(list(zip(data_postEmb, ids)),\n",
    "                        #batch_size=384,\n",
    "                        batch_size=100,\n",
    "                        shuffle=True,\n",
    "                        collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "canvas": {
     "comments": [],
     "componentType": "CodeCell",
     "copiedOriginId": null,
     "headerColor": "none",
     "id": "9c4a0bc1-9f7c-41ee-bde9-863d4f2ce3f7",
     "isComponent": false,
     "name": "",
     "parents": []
    },
    "id": "uv6winS6lJM4"
   },
   "outputs": [],
   "source": [
    "#train_loss_list=[]\n",
    "#val_accuracy=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "canvas": {
     "comments": [],
     "componentType": "CodeCell",
     "copiedOriginId": null,
     "headerColor": "none",
     "id": "37fca4a1-174b-4356-b27a-b934ffc95aea",
     "isComponent": false,
     "name": "",
     "parents": []
    },
    "id": "Ezc2SLLmlkFU"
   },
   "outputs": [],
   "source": [
    "#v12 -> v13 : linear layer 추가\n",
    "torch.save(net,\"/content/drive/MyDrive/BlogAuthorClass/Trained_models/GRUmodel_v13(Lifted0p05Pos01_Large384L2)\")\n",
    "#torch.save(net,\"/content/drive/MyDrive/BlogAuthorClass/Trained_models/GRUmodel_v13(Lifted0p005Pos001_Large384L2)\")\n",
    "np.save('/content/drive/MyDrive/BlogAuthorClass/Trained_models/v13_tr_loss(Lifted0p05Pos01_Large384L2)',train_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "canvas": {
     "comments": [],
     "componentType": "CodeCell",
     "copiedOriginId": null,
     "headerColor": "none",
     "id": "4c65c594-05d8-436b-ac4b-c6c7255741db",
     "isComponent": false,
     "name": "",
     "parents": []
    },
    "id": "YELOl7El3g6D"
   },
   "outputs": [],
   "source": [
    "net.cuda()\n",
    "#for data, labels in dataloader :\n",
    "#print(padded_seq.shape)\n",
    "#print(seq,seq.shape)\n",
    "#print(padded_seq[i,:end].shape)\n",
    "#padded_seq[i,:end] = seq\n",
    "#print(padded_seq)\n",
    "#with torch.no_grad() :\n",
    "for data,_,labels in dataloader :\n",
    "    net.train()   # dropout on\n",
    "    optimizer.zero_grad()\n",
    "    embeddings = net(data.to(device))\n",
    "    hard_pairs = miner(embeddings[0], labels)\n",
    "    loss = loss_func(embeddings[0], labels, hard_pairs)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "canvas": {
     "comments": [],
     "componentType": "CodeCell",
     "copiedOriginId": null,
     "headerColor": "none",
     "id": "0f9fe3df-92b6-4755-82a6-4312b404447b",
     "isComponent": false,
     "name": "",
     "parents": []
    },
    "id": "XwO3xaWL4eWe"
   },
   "outputs": [],
   "source": [
    "id_series = text['id'].unique()\n",
    "ind_list=[]\n",
    "for i in id_series :\n",
    "    ind = text[text[\"id\"]==i].index.to_list()\n",
    "    ind_list.append(ind)\n",
    "np.random.shuffle(ind_list)\n",
    "shuffled_ind = sum(ind_list, [])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "canvas": {
     "comments": [],
     "componentType": "CodeCell",
     "copiedOriginId": null,
     "headerColor": "none",
     "id": "429f2231-752e-4b03-9b87-997136e9b67e",
     "isComponent": false,
     "name": "",
     "parents": []
    },
    "id": "jS6BRZ7C5vd2"
   },
   "source": [
    "## id sampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "canvas": {
     "comments": [],
     "componentType": "CodeCell",
     "copiedOriginId": null,
     "headerColor": "none",
     "id": "3f956368-7626-4fd3-8d32-a78df0cebf2c",
     "isComponent": false,
     "name": "",
     "parents": []
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "N6uXhYpg5wHQ",
    "outputId": "41d8e0d3-3609-4fa7-baaf-4e8fcea05d52"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25ids\n",
      "Epoch : 0 Loss :  1851.730654001236\n",
      "1.0 422\n",
      "Epoch : 1 Loss :  1667.5867809057236\n",
      "1.0 422\n",
      "Epoch : 2 Loss :  1453.113211631775\n",
      "1.0 422\n",
      "Epoch : 3 Loss :  1398.6718192100525\n",
      "1.0 422\n",
      "Epoch : 4 Loss :  1418.0404500961304\n",
      "1.0 422\n",
      "Epoch : 5 Loss :  1540.956978559494\n",
      "1.0 422\n",
      "Epoch : 6 Loss :  1338.38130235672\n",
      "1.0 422\n",
      "Epoch : 7 Loss :  1371.8539288043976\n",
      "1.0 422\n",
      "Epoch : 8 Loss :  1328.3064476847649\n",
      "1.0 422\n",
      "Epoch : 9 Loss :  1298.9918791651726\n",
      "1.0 422\n",
      "Epoch : 10 Loss :  1268.7404308319092\n",
      "1.0 422\n",
      "Epoch : 11 Loss :  1458.278264760971\n",
      "1.0 422\n",
      "Epoch : 12 Loss :  1243.9856273531914\n",
      "1.0 422\n",
      "Epoch : 13 Loss :  1210.214589893818\n",
      "1.0 422\n",
      "Epoch : 14 Loss :  1218.032209098339\n",
      "1.0 422\n",
      "Epoch : 15 Loss :  1176.7303488254547\n",
      "1.0 422\n",
      "Epoch : 16 Loss :  1149.1760668158531\n",
      "1.0 422\n",
      "Epoch : 17 Loss :  1203.8077200651169\n",
      "1.0 422\n",
      "Epoch : 18 Loss :  1128.0074341893196\n",
      "1.0 422\n",
      "Epoch : 19 Loss :  1178.3327382802963\n",
      "1.0 422\n",
      "Epoch : 20 Loss :  1670.8216650485992\n",
      "1.0 422\n",
      "Epoch : 21 Loss :  1367.0105098485947\n",
      "1.0 422\n",
      "Epoch : 22 Loss :  1243.689822435379\n",
      "1.0 422\n",
      "Epoch : 23 Loss :  1150.9956321120262\n",
      "1.0 422\n",
      "Epoch : 24 Loss :  1116.770914644003\n",
      "1.0 422\n",
      "Epoch : 25 Loss :  1071.9276516139507\n",
      "1.0 422\n",
      "Epoch : 26 Loss :  1073.6293166279793\n",
      "1.0 422\n",
      "Epoch : 27 Loss :  1043.4224910736084\n",
      "1.0 422\n",
      "Epoch : 28 Loss :  1040.1952924132347\n",
      "1.0 422\n",
      "Epoch : 29 Loss :  1043.614962041378\n",
      "1.0 422\n",
      "Epoch : 0 Loss :  2335.656615614891\n",
      "1.0 422\n",
      "Epoch : 1 Loss :  2377.5202832221985\n",
      "1.0 422\n",
      "Epoch : 2 Loss :  2288.511756181717\n",
      "1.0 422\n",
      "Epoch : 3 Loss :  2256.436532020569\n",
      "1.0 422\n",
      "Epoch : 4 Loss :  2295.192983865738\n",
      "1.0 422\n",
      "Epoch : 5 Loss :  2257.685118198395\n",
      "1.0 422\n",
      "Epoch : 6 Loss :  2245.6227984428406\n",
      "1.0 422\n",
      "Epoch : 7 Loss :  2181.4019224643707\n",
      "1.0 422\n",
      "Epoch : 8 Loss :  2282.8305249214172\n",
      "1.0 422\n",
      "Epoch : 9 Loss :  2298.0568643808365\n",
      "1.0 422\n",
      "100ids\n",
      "Epoch : 0 Loss :  1354.6788821220398\n",
      "1.0 422\n",
      "Epoch : 1 Loss :  1161.1166053414345\n",
      "1.0 422\n",
      "Epoch : 2 Loss :  1097.7486251592636\n",
      "1.0 422\n",
      "Epoch : 3 Loss :  1045.0121607780457\n",
      "1.0 422\n",
      "Epoch : 4 Loss :  1013.6649228334427\n",
      "1.0 422\n",
      "Epoch : 5 Loss :  1049.8121085166931\n",
      "1.0 422\n",
      "Epoch : 6 Loss :  989.4043945670128\n",
      "1.0 422\n",
      "Epoch : 7 Loss :  953.1934248507023\n",
      "1.0 422\n",
      "Epoch : 8 Loss :  955.2616521716118\n",
      "1.0 422\n",
      "Epoch : 9 Loss :  955.7334040552378\n",
      "1.0 422\n",
      "Epoch : 10 Loss :  944.1890925467014\n",
      "1.0 422\n",
      "Epoch : 11 Loss :  958.2082096338272\n",
      "1.0 422\n",
      "Epoch : 12 Loss :  921.8295633792877\n",
      "1.0 422\n",
      "Epoch : 13 Loss :  947.9113275408745\n",
      "1.0 422\n",
      "Epoch : 14 Loss :  881.7091592252254\n",
      "1.0 422\n",
      "Epoch : 15 Loss :  864.6607555150986\n",
      "1.0 422\n",
      "Epoch : 16 Loss :  857.6979657709599\n",
      "1.0 422\n",
      "Epoch : 17 Loss :  870.011477664113\n",
      "1.0 422\n",
      "Epoch : 18 Loss :  878.9293124675751\n",
      "1.0 422\n",
      "Epoch : 19 Loss :  886.0765404701233\n",
      "1.0 422\n",
      "Epoch : 20 Loss :  863.0984731912613\n",
      "1.0 422\n",
      "Epoch : 21 Loss :  914.6510826647282\n",
      "1.0 422\n",
      "Epoch : 22 Loss :  867.2081773281097\n",
      "1.0 422\n",
      "Epoch : 23 Loss :  858.5883914083242\n",
      "1.0 422\n",
      "Epoch : 24 Loss :  849.7913216501474\n",
      "1.0 422\n",
      "Epoch : 25 Loss :  806.1069692969322\n",
      "1.0 422\n",
      "Epoch : 26 Loss :  795.7710222154856\n",
      "1.0 422\n",
      "Epoch : 27 Loss :  859.6730837225914\n",
      "1.0 422\n",
      "Epoch : 28 Loss :  799.6000373065472\n",
      "1.0 422\n",
      "Epoch : 29 Loss :  818.6280211726917\n",
      "1.0 422\n",
      "Epoch : 0 Loss :  1932.04776263237\n",
      "1.0 422\n",
      "Epoch : 1 Loss :  1993.7416260838509\n",
      "1.0 422\n",
      "Epoch : 2 Loss :  2019.2658154964447\n",
      "1.0 422\n",
      "Epoch : 3 Loss :  1975.5177087783813\n",
      "1.0 422\n",
      "Epoch : 4 Loss :  1983.479297041893\n",
      "1.0 422\n",
      "Epoch : 5 Loss :  1999.8094557523727\n",
      "1.0 422\n",
      "Epoch : 6 Loss :  1963.623638868332\n",
      "1.0 422\n",
      "Epoch : 7 Loss :  1951.497858762741\n",
      "1.0 422\n",
      "Epoch : 8 Loss :  1981.0167752504349\n",
      "1.0 422\n",
      "Epoch : 9 Loss :  1941.9327348470688\n",
      "1.0 422\n"
     ]
    }
   ],
   "source": [
    "# fixed train\n",
    "\n",
    "###\n",
    "print(\"25ids\")\n",
    "net.load_state_dict(torch.load('/content/drive/MyDrive/BlogAuthorClass/SampledID(2)/GRUmodel_v13(25ids)(2)').state_dict())\n",
    "\n",
    "data_postEmb = np.load('/content/drive/MyDrive/BlogAuthorClass/SampledID(2)/postEmb_384dim_25samples(train).npy',allow_pickle=True)\n",
    "text = pd.read_csv('/content/drive/MyDrive/BlogAuthorClass/SampledID(2)/blogtext_train_sample(25ids).csv')\n",
    "\n",
    "data_postEmb = [torch.tensor(sent_seq, device=device) for sent_seq in data_postEmb]\n",
    "ids = torch.tensor(list(text['id']))\n",
    "\n",
    "dataloader = DataLoader(list(zip(data_postEmb, ids)),\n",
    "                        #batch_size=100,\n",
    "                        batch_size=64,\n",
    "                        shuffle=True,\n",
    "                        collate_fn=collate_fn)\n",
    "\n",
    "miner = miners.TripletMarginMiner(margin=0.15,\n",
    "                          type_of_triplets=\"all\")  # all hard semihard easy\n",
    "loss_func = losses.LiftedStructureLoss(neg_margin=0.05, # baseline\n",
    "                                       pos_margin=0.01, # baseline\n",
    "\n",
    "                                       distance=distances.LpDistance(p=2.))#,normalize_embeddings=False))\n",
    "\n",
    "optimizer = optim.Adam(net.parameters(), lr = 0.001)   #0.00000005\n",
    "scheduler = optim.lr_scheduler.LambdaLR(optimizer=optimizer,\n",
    "                                        lr_lambda=lambda step: 0.98 ** step,\n",
    "                                        last_epoch=-1,\n",
    "                                        verbose=False)\n",
    "\n",
    "suc=0\n",
    "fal=0\n",
    "\n",
    "\n",
    "for epoch in range(30):\n",
    "    train_loss = 0\n",
    "    for data, _, labels in dataloader:\n",
    "        net.train()   # dropout on\n",
    "        try :\n",
    "            optimizer.zero_grad()\n",
    "            embeddings = net(data.cuda())\n",
    "            hard_pairs = miner(embeddings[0], labels)\n",
    "            loss = loss_func(embeddings[0], labels, hard_pairs)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "            gc.collect()\n",
    "            torch.cuda.empty_cache()\n",
    "            suc+=1\n",
    "        except Exception as e :\n",
    "            print(e)\n",
    "            fal+=1\n",
    "    scheduler.step()\n",
    "    #train_loss_list.append(train_loss / len(dataloader))\n",
    "    print(\"Epoch :\", epoch, \"Loss : \", train_loss)\n",
    "    print(suc/(suc+fal), suc)\n",
    "    suc=0\n",
    "    fal=0\n",
    "\n",
    "miner = miners.TripletMarginMiner(margin=0.15,\n",
    "                          type_of_triplets=\"all\")\n",
    "for epoch in range(10):\n",
    "    train_loss = 0\n",
    "    for data, _, labels in dataloader:\n",
    "        net.train()   # dropout on\n",
    "        try :\n",
    "            optimizer.zero_grad()\n",
    "            embeddings = net(data.cuda())\n",
    "            hard_pairs = miner(embeddings[0], labels)\n",
    "            loss = loss_func(embeddings[0], labels, hard_pairs)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "            gc.collect()\n",
    "            torch.cuda.empty_cache()\n",
    "            suc+=1\n",
    "        except Exception as e :\n",
    "            print(e)\n",
    "            fal+=1\n",
    "    scheduler.step()\n",
    "    #train_loss_list.append(train_loss / len(dataloader))\n",
    "    print(\"Epoch :\", epoch, \"Loss : \", train_loss)\n",
    "    print(suc/(suc+fal), suc)\n",
    "    suc=0\n",
    "    fal=0\n",
    "\n",
    "torch.save(net,\"/content/drive/MyDrive/BlogAuthorClass/SampledID(2)/GRUmodel_v13(25ids)(2)\")\n",
    "del data_postEmb, text\n",
    "\n",
    "\n",
    "###\n",
    "print(\"100ids\")\n",
    "net.load_state_dict(torch.load('/content/drive/MyDrive/BlogAuthorClass/SampledID(2)/GRUmodel_v13(25ids)(2)').state_dict())\n",
    "\n",
    "data_postEmb = np.load('/content/drive/MyDrive/BlogAuthorClass/SampledID(2)/postEmb_384dim_25samples(train).npy',allow_pickle=True)\n",
    "text = pd.read_csv('/content/drive/MyDrive/BlogAuthorClass/SampledID(2)/blogtext_train_sample(25ids).csv')\n",
    "\n",
    "data_postEmb = [torch.tensor(sent_seq, device=device) for sent_seq in data_postEmb]\n",
    "ids = torch.tensor(list(text['id']))\n",
    "\n",
    "dataloader = DataLoader(list(zip(data_postEmb, ids)),\n",
    "                        #batch_size=100,\n",
    "                        batch_size=64,\n",
    "                        shuffle=True,\n",
    "                        collate_fn=collate_fn)\n",
    "\n",
    "miner = miners.TripletMarginMiner(margin=0.15,\n",
    "                          type_of_triplets=\"all\")  # all hard semihard easy\n",
    "#loss_func = losses.LiftedStructureLoss(neg_margin=0.05, # baseline\n",
    "#                                       pos_margin=0.01, # baseline\n",
    "#                                       distance=distances.LpDistance(p=2.))#,normalize_embeddings=False))\n",
    "\n",
    "#optimizer = optim.Adam(net.parameters(), lr = 0.001)   #0.001\n",
    "#scheduler = optim.lr_scheduler.LambdaLR(optimizer=optimizer,\n",
    "#                                        lr_lambda=lambda step: 0.98 ** step,\n",
    "#                                        last_epoch=-1,\n",
    "#                                        verbose=False)\n",
    "\n",
    "suc=0\n",
    "fal=0\n",
    "\n",
    "\n",
    "for epoch in range(30):\n",
    "    train_loss = 0\n",
    "    for data, _, labels in dataloader:\n",
    "        net.train()   # dropout on\n",
    "        try :\n",
    "            optimizer.zero_grad()\n",
    "            embeddings = net(data.cuda())\n",
    "            hard_pairs = miner(embeddings[0], labels)\n",
    "            loss = loss_func(embeddings[0], labels, hard_pairs)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "            gc.collect()\n",
    "            torch.cuda.empty_cache()\n",
    "            suc+=1\n",
    "        except Exception as e :\n",
    "            print(e)\n",
    "            fal+=1\n",
    "    scheduler.step()\n",
    "    #train_loss_list.append(train_loss / len(dataloader))\n",
    "    print(\"Epoch :\", epoch, \"Loss : \", train_loss)\n",
    "    print(suc/(suc+fal), suc)\n",
    "    suc=0\n",
    "    fal=0\n",
    "\n",
    "miner = miners.TripletMarginMiner(margin=0.15,\n",
    "                          type_of_triplets=\"all\")\n",
    "for epoch in range(10):\n",
    "    train_loss = 0\n",
    "    for data, _, labels in dataloader:\n",
    "        net.train()   # dropout on\n",
    "        try :\n",
    "            optimizer.zero_grad()\n",
    "            embeddings = net(data.cuda())\n",
    "            hard_pairs = miner(embeddings[0], labels)\n",
    "            loss = loss_func(embeddings[0], labels, hard_pairs)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "            gc.collect()\n",
    "            torch.cuda.empty_cache()\n",
    "            suc+=1\n",
    "        except Exception as e :\n",
    "            print(e)\n",
    "            fal+=1\n",
    "    #scheduler.step()\n",
    "    #train_loss_list.append(train_loss / len(dataloader))\n",
    "    print(\"Epoch :\", epoch, \"Loss : \", train_loss)\n",
    "    print(suc/(suc+fal), suc)\n",
    "    suc=0\n",
    "    fal=0\n",
    "\n",
    "torch.save(net,\"/content/drive/MyDrive/BlogAuthorClass/SampledID(2)/GRUmodel_v13(25ids)(2)\")\n",
    "del data_postEmb, text "
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "canvas": {
   "colorPalette": [
    "inherit",
    "inherit",
    "inherit",
    "inherit",
    "inherit",
    "inherit",
    "inherit",
    "inherit",
    "inherit",
    "inherit"
   ],
   "parameters": [],
   "version": "1.0"
  },
  "colab": {
   "machine_shape": "hm",
   "provenance": []
  },
  "gpuClass": "premium",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
